# -*- coding: utf-8 -*-
"""topic_modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vmt3AYtCIWj-vr_Yq20KfXe7zBcw5nok
"""

!pip install sentence_transformers umap hdbscan wordcloud nltk gensim pyldavis spacy bertopic openai
import pandas as pd
import openai
from bertopic.representation import OpenAI
import numpy as np
from sentence_transformers import SentenceTransformer
import umap
from umap import UMAP
from hdbscan import HDBSCAN
import nltk
from nltk.corpus import stopwords
import seaborn as sns
import matplotlib.pyplot as plt
import collections
import spacy
from wordcloud import WordCloud, STOPWORDS
from sklearn.feature_extraction.text import CountVectorizer
from bertopic import BERTopic
from bertopic.vectorizers import ClassTfidfTransformer
from bertopic.representation import KeyBERTInspired
from bertopic.representation import PartOfSpeech
from bertopic.representation import MaximalMarginalRelevance
nltk.download('stopwords')

class TopicModeling():


  def __init__(self,df):
    self.df = df

  def head(self):
    """
    Print first 5 values of dataframe.
    """
    return self.df.head()

  def eda(self):
    """
    Perform some preliminary analysis on the dataframe.

    return: number of songs per album, length of lyrics,
    and histogram showing distribution of lyric character
    length.
    """
    print(self.df['Album'].value_counts())
    print('')
    print("Number of songs: ", len(self.df['Lyric']))
    num_char = sns.histplot(self.df['Lyric'].str.len())
    print('')
    num_nan = print("Number of missing values: ",self.df.isnull().sum().sum())
    num_nan_loc = self.df.isna().sum()
    return num_char, num_nan, num_nan_loc


  def stop_combine(self, stop1, stop2):
    """
    Combine stopword lists from different libraries for
    processing in BERTopic model.

    param1: stopword list 1
    param2: stopwords list 2
    return: combined stopword list
    """
    stop_words = set(stop1) | set(stop2)
    stop_words = list(stop_words)
    newStopWords = ['bring', 'yeah', 'let', 'oh', 'like', 'let', 'i\'m','i\'ll',
                    'i\'ve','got', 'khalid']
    stop_words.extend(newStopWords)
    return stop_words

  def corpus(self):
    """
    Creates a corpus of text from the 'Lyric' column for
    further exploratory analysis.

    return: corpus
    """
    corpus = []
    lyr_words = self.df['Lyric'].str.split()
    lyr_words = lyr_words.values.tolist()
    corpus = [word for i in lyr_words for word in i]
    return corpus

  def most_common_words(self, corpus, stop):
    """
    Creates a plot of the most common words in corpus.

    param1: corpus of text
    param2: stopwords list
    return: plot of most common words in corpus
    """
    counter = collections.Counter(corpus)
    most_common = counter.most_common()
    x, y = [], []
    for word,count in most_common[:60]:
      if (word not in stop):
        x.append(word)
        y.append(count)
    common_plot = sns.barplot(x=y,y=x)
    return common_plot

  def generate_WC(self, stopwords):
    """
    Generate a wordcloud from 'Lyric' column

    param: stopwords list
    return: wordcloud
    """
    wordcloud = WordCloud(
        background_color='white',
        stopwords = stopwords,
        max_words=60,
        max_font_size=30,
        scale = 3
    )
    wordcloud = wordcloud.generate(self.df['Lyric'].str.cat(sep=' '))
    fig = plt.figure(1, figsize=(12, 12))
    plt.axis('off')

    plt.imshow(wordcloud)
    plt.show()

  def col_tolist(self):
    """
    Converts dataframe column to list for BERTopic modeling

    returns: list
    """
    lyr_list = self.df['Lyric'].tolist()
    return lyr_list

  def bert_model_inst(self, stopwords):
    """
    Create a BERTopic object with set parameters to
    call upon.

    param: stopwords list
    return: BERTopic model object
    """
    vec_model = CountVectorizer(stop_words=stopwords)
    embedding_model = SentenceTransformer('all-mpnet-base-v2')
    ctfidf_model = ClassTfidfTransformer(bm25_weighting=True)
    hdbscan_model = HDBSCAN(min_cluster_size=2, metric='euclidean',
                            cluster_selection_method='eom',
                            prediction_data=True)
    umap_model = UMAP(n_neighbors=2,
                      metric='cosine', low_memory=False)

    main_representation = KeyBERTInspired()
    aspect_model2 = PartOfSpeech("en_core_web_sm")
    client = openai.OpenAI(api_key="sk-...")
    aspect_model1 = OpenAI(client, model="gpt-3.5-turbo", chat=True)

    representation_model = {
    "Main":main_representation,
    "Aspect1":aspect_model1,
    "Aspect2":aspect_model2}

    model = BERTopic(
       hdbscan_model=hdbscan_model,
       vectorizer_model = vec_model,
       embedding_model = embedding_model,
       ctfidf_model = ctfidf_model,
       representation_model = representation_model,
       umap_model = umap_model,
       calculate_probabilities=True,
       verbose=True)
    return model

  def bert_model(self, model, lyr_list):
    """
    Fit and transform a provided list to BERTopic model.

    param1: BERTopic model object
    param2: list
    return: generated topics, their probabilities, and
    transformed model
    """
    topics, probs = model.fit_transform(lyr_list)
    return topics, probs, model

  def get_single_list(self):
    """
    Get a list of albums that only have one song.

    return: list
    """
    df_group = self.df.groupby('Album')
    single_list = list()
    for Album_Name, DataFrame in df_group:
      if DataFrame.shape[0] == 1:
        single_list.append(Album_Name)
    return single_list

  def get_lyr_lists(self, single_list):
    """
    Replace NaN and single album values with 'Single', drop entries
    that do not have lyrics published yet, and generate a dictionary
    that maps a list of songs within an album to the album name.

    param: list of singles albums
    return: dictionary
    """
    clean_df = self.df
    clean_df = clean_df.drop(clean_df[clean_df['Lyric'].str.len() < 95].index)
    df_group = clean_df.groupby('Album')
    clean_df['Album'].fillna('Single', inplace=True)
    for single in single_list:
      clean_df.replace(single, 'Single', inplace=True)
    lyric_dict = {}
    for Album_Name, Data_Frame in df_group:
      lyric_dict[Album_Name] = list(Data_Frame['Lyric'])
    return lyric_dict

  def topic_interpretation(self, topic_list):
    """
    Call on OpenAI API to take in the list of words generated in a
    topic and provide a description encapsulating the overarching theme.

    param: list of topic words
    return: description
    """
    openai.api_key = "sk-..."
    client = openai.OpenAI(api_key=openai.api_key)

    prompt = f"Based on the following words from song lyrics, what would be an appropriate topic? {', '.join(topic_list)}."
    response = client.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": prompt}
      ]
    )

    return(response.choices[0].message.content)

df = TopicModeling(pd.read_csv('Khalid.csv'))
df.head()

df.eda()

corpus = df.corpus()
stop1 = stopwords.words('english')
en = spacy.load('en_core_web_sm')
stop2 = en.Defaults.stop_words
stopwords = df.stop_combine(stop1, stop2)
most_common = df.most_common_words(corpus, stopwords)

wc_stop = set(STOPWORDS)
df.generate_WC(stopwords)

lyr_list = df.col_tolist()
bert_model = df.bert_model_inst(stopwords)
topics, probs, model = df.bert_model(bert_model,lyr_list)

model.get_topic_info()

openai_call1 = model.get_topic_info()['Representation'][1]
representation_call = model.get_topic_info()['Aspect1'][1]

print(openai_call1)

response = df.topic_interpretation(openai_call1)
print(response)

print(representation_call)

model.visualize_documents(lyr_list)

hierarchical_topics = model.hierarchical_topics(lyr_list)

model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)

model.visualize_topics()

model.visualize_heatmap()

model.visualize_barchart()

single_list = df.get_single_list()
lyr_dict = df.get_lyr_lists(single_list)
singles_lyr = lyr_dict['Single']

bert_model_1 = df.bert_model_inst(stopwords)
topics1, probs1, model1 = df.bert_model(bert_model_1,singles_lyr)

model1.get_topic_info()

model1.visualize_barchart()

bert_model_2 = df.bert_model_inst(stopwords)
topics2, probs2, model2 = df.bert_model(bert_model_2,lyr_dict['American Teen'])

model2.get_topic_info()

model2.visualize_barchart()

bert_model_3 = df.bert_model_inst(stopwords)
topics3, probs3, model3 = df.bert_model(bert_model_3,lyr_dict['Free Spirit'])

model3.get_topic_info()

model3.visualize_barchart()